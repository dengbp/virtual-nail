import cv2
import numpy as np
import torch
from PIL import Image
from pathlib import Path
import os
# V44: åˆ‡æ¢åˆ°IP-Adapteræ–¹æ¡ˆï¼Œå¹¶ä»æœ¬åœ°åŠ è½½æ¨¡å‹
from diffusers import StableDiffusionXLInpaintPipeline, AutoencoderKL
from huggingface_hub import hf_hub_download
import time
import sys
import argparse
from diffusers import StableDiffusionXLPipeline
import requests
import base64
from io import BytesIO
import threading
from datetime import datetime

# WebUI è¿›åº¦ç›‘æ§å·¥å…·ç±»
class WebUIProgressMonitor:
    """WebUI è¿›åº¦ç›‘æ§å·¥å…·ç±»"""
    
    @staticmethod
    def get_progress_via_http():
        """é€šè¿‡ HTTP æ¥å£è·å–è¿›åº¦"""
        try:
            response = requests.get("http://127.0.0.1:7860/sdapi/v1/progress", timeout=5)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"HTTPè¿›åº¦è·å–å¤±è´¥: {e}")
        return None
    
    @staticmethod
    def get_queue_status():
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        try:
            response = requests.get("http://127.0.0.1:7860/sdapi/v1/queue", timeout=5)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"é˜Ÿåˆ—çŠ¶æ€è·å–å¤±è´¥: {e}")
        return None
    
    @staticmethod
    def get_task_info():
        """è·å–å½“å‰ä»»åŠ¡ä¿¡æ¯"""
        try:
            response = requests.get("http://127.0.0.1:7860/sdapi/v1/queue", timeout=5)
            if response.status_code == 200:
                queue_data = response.json()
                return {
                    'queue_running': queue_data.get('queue_running', []),
                    'queue_pending': queue_data.get('queue_pending', []),
                    'queue_history': queue_data.get('queue_history', [])
                }
        except Exception as e:
            print(f"ä»»åŠ¡ä¿¡æ¯è·å–å¤±è´¥: {e}")
        return None
    
    @staticmethod
    def find_task_by_prompt(task_info, target_prompt_keywords=None, task_id=None):
        """æ ¹æ®æç¤ºè¯å…³é”®è¯æˆ–ä»»åŠ¡IDæŸ¥æ‰¾ç‰¹å®šä»»åŠ¡"""
        if not task_info:
            return None
            
        # æœç´¢æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        for task in task_info.get('queue_running', []):
            if task_id and task.get('id') == task_id:
                return {'status': 'running', 'task': task}
            
            if target_prompt_keywords:
                prompt = task.get('prompt', '')
                if any(keyword.lower() in prompt.lower() for keyword in target_prompt_keywords):
                    return {'status': 'running', 'task': task}
        
        # æœç´¢ç­‰å¾…ä¸­çš„ä»»åŠ¡
        for task in task_info.get('queue_pending', []):
            if task_id and task.get('id') == task_id:
                return {'status': 'pending', 'task': task}
            
            if target_prompt_keywords:
                prompt = task.get('prompt', '')
                if any(keyword.lower() in prompt.lower() for keyword in target_prompt_keywords):
                    return {'status': 'pending', 'task': task}
        
        # æœç´¢å†å²ä»»åŠ¡
        for task in task_info.get('queue_history', []):
            if task_id and task.get('id') == task_id:
                return {'status': 'completed', 'task': task}
            
            if target_prompt_keywords:
                prompt = task.get('prompt', '')
                if any(keyword.lower() in prompt.lower() for keyword in target_prompt_keywords):
                    return {'status': 'completed', 'task': task}
        
        return None
    
    @staticmethod
    def monitor_specific_task(task_identifier, callback=None, timeout=300):
        """
        ç›‘æ§ç‰¹å®šä»»åŠ¡çš„è¿›åº¦
        task_identifier: å¯ä»¥æ˜¯ä»»åŠ¡IDæˆ–æç¤ºè¯å…³é”®è¯åˆ—è¡¨
        """
        start_time = time.time()
        task_found = False
        
        while time.time() - start_time < timeout:
            try:
                # è·å–ä»»åŠ¡ä¿¡æ¯
                task_info = WebUIProgressMonitor.get_task_info()
                if not task_info:
                    time.sleep(2)
                    continue
                
                # æŸ¥æ‰¾ç‰¹å®šä»»åŠ¡
                if isinstance(task_identifier, str):
                    # æŒ‰ä»»åŠ¡IDæŸ¥æ‰¾
                    task_result = WebUIProgressMonitor.find_task_by_prompt(task_info, task_id=task_identifier)
                else:
                    # æŒ‰æç¤ºè¯å…³é”®è¯æŸ¥æ‰¾
                    task_result = WebUIProgressMonitor.find_task_by_prompt(task_info, target_prompt_keywords=task_identifier)
                
                if task_result:
                    task_found = True
                    status = task_result['status']
                    task = task_result['task']
                    
                    if status == 'running':
                        # è·å–è¯¦ç»†è¿›åº¦
                        progress_data = WebUIProgressMonitor.get_progress_via_http()
                        if progress_data:
                            state = progress_data.get('state', {})
                            current_step = state.get('sampling_step', 0)
                            total_steps = state.get('sampling_steps', 30)
                            
                            if total_steps > 0:
                                progress_percent = (current_step / total_steps) * 100
                                status_msg = f"ä»»åŠ¡è¿›åº¦: {current_step}/{total_steps} ({progress_percent:.1f}%)"
                                print(status_msg)
                                
                                if callback:
                                    callback(current_step, total_steps, progress_percent, task)
                                
                                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                                if current_step >= total_steps:
                                    print(f"ä»»åŠ¡ {task.get('id', 'unknown')} å·²å®Œæˆï¼")
                                    return True
                    
                    elif status == 'pending':
                        print(f"ä»»åŠ¡ {task.get('id', 'unknown')} æ­£åœ¨ç­‰å¾…ä¸­...")
                    
                    elif status == 'completed':
                        print(f"ä»»åŠ¡ {task.get('id', 'unknown')} å·²å®Œæˆï¼")
                        return True
                
                else:
                    if task_found:
                        print("ä»»åŠ¡å·²å®Œæˆæˆ–å·²ä»é˜Ÿåˆ—ä¸­ç§»é™¤")
                        return True
                    else:
                        print("æœªæ‰¾åˆ°æŒ‡å®šä»»åŠ¡ï¼Œç»§ç»­æœç´¢...")
                
                time.sleep(2)  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                print(f"ä»»åŠ¡ç›‘æ§å‡ºé”™: {e}")
                time.sleep(2)
        
        print(f"ä»»åŠ¡ç›‘æ§è¶…æ—¶ ({timeout}ç§’)")
        return False
    
    @staticmethod
    def monitor_progress_http(callback=None):
        """HTTPæ–¹å¼ç›‘æ§è¿›åº¦"""
        while True:
            progress_data = WebUIProgressMonitor.get_progress_via_http()
            if progress_data:
                state = progress_data.get('state', {})
                current_step = state.get('sampling_step', 0)
                total_steps = state.get('sampling_steps', 30)
                job = state.get('job', '')
                
                if current_step > 0 and total_steps > 0:
                    progress_percent = (current_step / total_steps) * 100
                    status_msg = f"AIç²¾ç‚¼è¿›åº¦: {current_step}/{total_steps} ({progress_percent:.1f}%)"
                    print(status_msg)
                    
                    if callback:
                        callback(current_step, total_steps, progress_percent)
                    
                    # å¦‚æœå¤„ç†å®Œæˆï¼Œé€€å‡ºç›‘æ§
                    if job == '':
                        print("AIç²¾ç‚¼å¤„ç†å®Œæˆï¼")
                        break
                elif job == '':
                    # æ²¡æœ‰ä»»åŠ¡åœ¨è¿è¡Œ
                    break
            
            time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
    
    @staticmethod
    def monitor_progress_websocket(callback=None):
        """WebSocketæ–¹å¼ç›‘æ§è¿›åº¦ï¼ˆéœ€è¦å®‰è£…websocket-clientï¼‰"""
        try:
            import websocket
            import json
            
            def on_message(ws, message):
                try:
                    data = json.loads(message)
                    if 'type' in data and data['type'] == 'progress':
                        current_step = data.get('data', {}).get('value', 0)
                        total_steps = data.get('data', {}).get('max', 30)
                        if total_steps > 0:
                            progress_percent = (current_step / total_steps) * 100
                            status_msg = f"AIç²¾ç‚¼è¿›åº¦: {current_step}/{total_steps} ({progress_percent:.1f}%)"
                            print(status_msg)
                            
                            if callback:
                                callback(current_step, total_steps, progress_percent)
                except Exception as e:
                    print(f"WebSocketæ¶ˆæ¯è§£æå¤±è´¥: {e}")
            
            def on_error(ws, error):
                print(f"WebSocketé”™è¯¯: {error}")
            
            def on_close(ws, close_status_code, close_msg):
                print("WebSocketè¿æ¥å…³é—­")
            
            def on_open(ws):
                print("WebSocketè¿æ¥å·²å»ºç«‹ï¼Œå¼€å§‹ç›‘æ§è¿›åº¦...")
            
            # è¿æ¥WebUIçš„WebSocket
            ws = websocket.WebSocketApp(
                "ws://127.0.0.1:7860/queue/join",
                on_open=on_open,
                on_message=on_message,
                on_error=on_error,
                on_close=on_close
            )
            ws.run_forever()
            
        except ImportError:
            print("WebSocketç›‘æ§éœ€è¦å®‰è£… websocket-client: pip install websocket-client")
            print("å›é€€åˆ°HTTPç›‘æ§æ–¹å¼...")
            WebUIProgressMonitor.monitor_progress_http(callback)
        except Exception as e:
            print(f"WebSocketç›‘æ§å¤±è´¥: {e}")
            print("å›é€€åˆ°HTTPç›‘æ§æ–¹å¼...")
            WebUIProgressMonitor.monitor_progress_http(callback)

class SDXLRefiner:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self._load_models()

    def _load_models(self):
        print("å¼€å§‹åŠ è½½SDXL + IP-Adapterç²¾ç‚¼æ¨¡å‹ (V52 - safetensors ä¼˜å…ˆ)...")
        start_time = time.time()
        
        base_model_path = "stabilityai/stable-diffusion-xl-base-1.0"
        
        # V52: ä¼˜å…ˆåŠ è½½ safetensorsï¼Œå¹¶è®©åº“è‡ªåŠ¨å¤„ç†ç¼“å­˜
        self.pipe = StableDiffusionXLInpaintPipeline.from_pretrained(
            base_model_path,
            torch_dtype=torch.float16,
            variant="fp16",
            use_safetensors=True
        )
        self.pipe = self.pipe.to(self.device)

        # V62: é™çº§ transformers åï¼Œä½¿ç”¨æœ€ç»ˆè¢«è¯å®çš„æœ¬åœ° .pth æ–‡ä»¶è·¯å¾„
        local_snapshots_path = "C:/Users/Administrator/.cache/huggingface/hub/models--h94--IP-Adapter/snapshots"
        
        self.pipe.load_ip_adapter(local_snapshots_path, subfolder="local-xl", weight_name="ip-adapter_xl.pth")
        self.pipe.set_ip_adapter_scale(0.7)

        print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨é™çº§ç­–ç•¥ï¼Œè€—æ—¶: {time.time() - start_time:.2f}ç§’")

    def refine_image(self, image_path: str, mask_path: str):
        """
        (V44 - æœ¬åœ°IP-Adapter) - ä½¿ç”¨æˆ‘ä»¬æ‰‹åŠ¨ä¸‹è½½çš„æ¨¡å‹è¿›è¡Œé«˜ä¿çœŸé£æ ¼è¿ç§»ã€‚
        """
        print(f"\n--- [AIç²¾ç‚¼é˜¶æ®µ V44 - æœ¬åœ°IP-Adapter] å¼€å§‹å¤„ç†: {image_path} ---")
        
        pixel_transplant_img = cv2.imread(image_path)
        if pixel_transplant_img is None:
            print(f"é”™è¯¯: æ— æ³•è¯»å–åƒç´ è¿ç§»å›¾åƒ {image_path}")
            return None, None
        
        # ç»Ÿä¸€åˆ†è¾¨ç‡
        h0, w0, _ = pixel_transplant_img.shape
        max_side = max(h0, w0)
        if max_side > 1024:
            new_h, new_w = (1024, int(w0 * 1024 / h0)) if h0 >= w0 else (int(h0 * 1024 / w0), 1024)
        else:
            new_h, new_w = h0, w0
        
        pixel_transplant_img_resized = cv2.resize(pixel_transplant_img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
        pixel_transplant_pil = Image.fromarray(cv2.cvtColor(pixel_transplant_img_resized, cv2.COLOR_BGR2RGB))
        
        debug_dir = Path("data/debug")
        debug_dir.mkdir(exist_ok=True)
        
        # åŠ è½½å¹¶å¤„ç†æ©ç 
        final_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if final_mask is None:
            print(f"é”™è¯¯: æ— æ³•ä» {mask_path} åŠ è½½æƒå¨æ©ç ")
            return None, None
        final_mask_resized = cv2.resize(final_mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)
        mask_pil = Image.fromarray(final_mask_resized)
        
        # æ³¨æ„ï¼šåœ¨åº•å±‚åŠ è½½æ–¹å¼ä¸­ï¼Œæˆ‘ä»¬ä¸å†éœ€è¦set_ip_adapter_scale

        prompt = (
            "Ultra-realistic, professional nail art photography. "
            "Extremely high-quality gel polish with a glossy, wet-look finish. "
            "Perfect 3D curvature, seamless cuticle integration, natural growth appearance. "
            "Sharp studio lighting, vibrant colors, intricate details preserved."
        )
        negative_prompt = "blurry, noisy, flat, matte, dull, deformed hand, bad lighting, color shift, pattern change, washed out, ugly"
        
        refined_pil = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=pixel_transplant_pil,
            mask_image=mask_pil,
            ip_adapter_image=pixel_transplant_pil,
            strength=0.8,
            num_inference_steps=30,
            guidance_scale=7.5
        ).images[0]
        
        refined_bgr = cv2.cvtColor(np.array(refined_pil), cv2.COLOR_RGB2BGR)

        # æœ€ç»ˆåˆæˆ
        output_image = pixel_transplant_img_resized.copy()
        output_image[final_mask_resized == 255] = refined_bgr[final_mask_resized == 255]
        
        # ä¿å­˜ç»“æœ
        input_stem = Path(image_path).stem
        output_dir = Path("data/output/final_refined")
        output_dir.mkdir(exist_ok=True)
        output_filename = f"{input_stem}_refined_v46.png"
        output_path = output_dir / output_filename
        cv2.imwrite(str(output_path), output_image)
        
        # ä¿å­˜è°ƒè¯•å›¾
        comparison = np.hstack([pixel_transplant_img_resized, refined_bgr, output_image])
        cv2.imwrite(str(debug_dir / f"{Path(input_stem)}_v46_comparison.png"), comparison)
        
        print(f"\nIP-Adapter (åº•å±‚åŠ è½½) Controlå®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_path}")
        print("V46æŠ€æœ¯æ–¹æ¡ˆï¼šåº•å±‚IP-Adapteræ‰‹åŠ¨åŠ è½½")
        return str(output_path), final_mask_resized

def process_refine(img_path, mask_path):
    """
    ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œå°è£…äº†ç²¾ç‚¼è¿‡ç¨‹çš„ä¸»è¦é€»è¾‘ã€‚
    ç°åœ¨ç”± API æœåŠ¡å™¨ç›´æ¥è°ƒç”¨ã€‚
    """
    start_time = time.time()
    
    # æ³¨æ„ï¼šè¿™é‡Œçš„ refiner å®ä¾‹å°†ç”±è°ƒç”¨æ–¹ï¼ˆAPIæœåŠ¡å™¨ï¼‰ä¼ å…¥æˆ–ç®¡ç†
    # ä¸ºäº†ä¿æŒæ­¤æ–‡ä»¶çš„æ¨¡å—åŒ–ï¼Œæˆ‘ä»¬å‡è®¾ refiner å·²è¢«æ­£ç¡®åˆå§‹åŒ–
    # ä½†åœ¨è¿™ä¸ªæ–‡ä»¶çš„ç‹¬ç«‹ç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå·±åˆå§‹åŒ–
    try:
        from refine_api_server import refiner_instance
    except (ImportError, NameError):
        print("è­¦å‘Š: æ— æ³•ä»APIæœåŠ¡å™¨å¯¼å…¥å…¨å±€refinerå®ä¾‹ã€‚å°†åˆ›å»ºä¸€ä¸ªæ–°çš„å®ä¾‹ã€‚")
        refiner_instance = SDXLRefiner()

    refined_img_path, _ = refiner_instance.refine_image(img_path, mask_path)
    
    if refined_img_path:
        # é‡å‘½åæ–‡ä»¶ï¼Œå‡†å¤‡æœ€ç»ˆè¾“å‡º
        final_output_path = Path(refined_img_path).with_name(f"{Path(img_path).stem}_final.png")
        if os.path.exists(final_output_path):
            os.remove(final_output_path)
        os.rename(refined_img_path, final_output_path)
        
        print(f"\n--- ç²¾ç‚¼æµç¨‹ç»“æŸ ---")
        print(f"ç»“æœå·²ä¿å­˜: {final_output_path}")
        print(f"è€—æ—¶: {time.time() - start_time:.2f}ç§’")
        
        return str(final_output_path)
    else:
        print("AIç²¾ç‚¼æ­¥éª¤å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
        return None

# V49: ç§»é™¤ __main__ æ¨¡å—ã€‚
# è¿™ä¸ªè„šæœ¬ç°åœ¨ä½œä¸ºä¸€ä¸ªæ¨¡å—è¢« API æœåŠ¡å™¨å¯¼å…¥ï¼Œä¸å†éœ€è¦ç‹¬ç«‹æ‰§è¡Œã€‚

# V63: æ·»åŠ ä¸€ä¸ªä¸´æ—¶çš„ main å—ï¼Œç”¨äºç‹¬ç«‹æµ‹è¯•æ¨¡å‹åŠ è½½
if __name__ == '__main__':
    print("--- [ç‹¬ç«‹æµ‹è¯•] å¼€å§‹æ‰§è¡Œæ¨¡å‹åŠ è½½ ---")
    try:
        # ç¡®ä¿è°ƒè¯•æ—¶èƒ½çœ‹åˆ°æ‰€æœ‰æ—¥å¿—
        import logging
        logging.basicConfig(level=logging.INFO)
        
        refiner = SDXLRefiner()
        print("--- [ç‹¬ç«‹æµ‹è¯•] æ¨¡å‹åŠ è½½æˆåŠŸ ---")
    except Exception as e:
        print(f"--- [ç‹¬ç«‹æµ‹è¯•] æ¨¡å‹åŠ è½½å¤±è´¥ ---")
        import traceback
        traceback.print_exc()

# ========== ä¸»æµç¨‹å…¥å£å‡½æ•° ========== 
def refine_sdxl_pipeline(orig_img, orig_stem):
    """
    ä¸»æµç¨‹å…¥å£ï¼šæ ¹æ®è¾“å…¥å›¾ç‰‡è·¯å¾„ï¼ˆå¯ä»¥æ˜¯åŸå›¾ã€åƒç´ è¿ç§»å›¾æˆ–è¡¥å…‰åå›¾ï¼‰ï¼Œè‡ªåŠ¨æ¨å¯¼æ©ç è·¯å¾„ï¼Œå®Œæˆç²¾ç‚¼ã€‚
    å‚æ•°ï¼š
        orig_img: PIL.Image.Imageï¼Œè¾“å…¥PILå›¾ç‰‡å¯¹è±¡
        orig_stem: strï¼Œè¾“å…¥å›¾ç‰‡çš„åŸå§‹æ–‡ä»¶åï¼ˆä¸åŒ…æ‹¬æ‰©å±•åï¼‰
    è¿”å›ï¼š
        out_path: strï¼Œæœ€ç»ˆç²¾ç‚¼æˆå“å›¾è·¯å¾„
    """
    from pathlib import Path
    import os
    import base64
    from PIL import Image
    import requests
    from io import BytesIO
    import numpy as np
    import cv2
    import time

    # 1. è¯»å–è¾“å…¥å›¾ï¼Œç¡®å®šç›®æ ‡å°ºå¯¸
    if isinstance(orig_img, Image.Image):
        img = orig_img
        tmp_input_path = 'data/output/debug/_tmp_refine_input.png'
        img.save(tmp_input_path)
        orig_img_path = tmp_input_path
    else:
        img = Image.open(orig_img)
        orig_img_path = orig_img
    orig_w, orig_h = img.size
    max_side = max(orig_w, orig_h)
    if max_side > 1024:
        if orig_w >= orig_h:
            target_w, target_h = 1024, int(orig_h * 1024 / orig_w)
        else:
            target_w, target_h = int(orig_w * 1024 / orig_h), 1024
    else:
        target_w, target_h = orig_w, orig_h

    # 2. ç”¨orig_stemæ‹¼æ©ç è·¯å¾„
    mask_path = f"data/test_masks/{orig_stem}_mask.png"
    if not os.path.exists(mask_path):
        raise FileNotFoundError(f"æ©ç æ–‡ä»¶ä¸å­˜åœ¨: {mask_path}")
    def process_mask(mask_path, target_size, use_binary=False, mask_quality='high'):
        """
        å¤„ç†æ©ç ï¼Œæ”¯æŒå¤šç§è´¨é‡æ¨¡å¼
        
        Args:
            mask_path: æ©ç æ–‡ä»¶è·¯å¾„
            target_size: ç›®æ ‡å°ºå¯¸ (width, height)
            use_binary: æ˜¯å¦ä½¿ç”¨äºŒå€¼åŒ–
            mask_quality: æ©ç è´¨é‡æ¨¡å¼ ('high', 'medium', 'low')
        """
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            raise FileNotFoundError(f"æ— æ³•è¯»å–æ©ç : {mask_path}")
        
        target_w, target_h = target_size
        
        if use_binary:
            # äºŒå€¼åŒ–å¤„ç†ï¼ˆä¸æ¨èï¼Œä½†ä¿ç•™é€‰é¡¹ï¼‰
            _, mask_bin = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY + cv2.OTSU)
            contours, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            clean_mask = np.zeros_like(mask_bin)
            for cnt in contours:
                if cv2.contourArea(cnt) > 100:
                    cv2.drawContours(clean_mask, [cnt], -1, 255, thickness=cv2.FILLED)
            # äºŒå€¼åŒ–éœ€è¦æ›´å¼ºçš„æ¨¡ç³Š
            feathered = cv2.GaussianBlur(clean_mask, (15, 15), 0)
        else:
            # ç°åº¦æ©ç å¤„ç†ï¼ˆæ¨èï¼‰
            if mask_quality == 'high':
                # é«˜è´¨é‡ï¼šä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œè½»å¾®æ¨¡ç³Š
                feathered = cv2.GaussianBlur(mask, (3, 3), 0)
            elif mask_quality == 'medium':
                # ä¸­ç­‰è´¨é‡ï¼šå¹³è¡¡ç»†èŠ‚å’Œå¹³æ»‘
                feathered = cv2.GaussianBlur(mask, (5, 5), 0)
            else:  # 'low'
                # ä½è´¨é‡ï¼šæ›´å¼ºæ¨¡ç³Šï¼Œæ›´å¹³æ»‘
                feathered = cv2.GaussianBlur(mask, (7, 7), 0)
        
        # è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
        feathered = cv2.resize(feathered, (target_w, target_h), interpolation=cv2.INTER_LINEAR)
        pil_mask = Image.fromarray(feathered)
        return pil_mask
    mask_pil = process_mask(mask_path, (target_w, target_h), use_binary=False, mask_quality='high')
    buf = BytesIO()
    mask_pil.save(buf, format="PNG")
    mask_b64 = base64.b64encode(buf.getvalue()).decode()

    # 3. ç»„è£…promptï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    lora1 = "Mastering_Manicure_A_Visual_Guide_to_Nail_Art_Techniques"
    lora2 = "Stiletto_Nails"
    lora1_weight = 0.8  # é™ä½æƒé‡ï¼Œå‡å°‘è¿‡åº¦é£æ ¼åŒ–
    lora2_weight = 1.2  # å¢å¼ºå°–å¤´æŒ‡ç”²æ•ˆæœ
    prompt_str = (
        f"<lora:{lora1}:{lora1_weight}> <lora:{lora2}:{lora2_weight}> "
        "nail art, stiletto nails, long sharp tip, professional manicure, natural curved nail shape, arched nail surface, 3D, convex, "
        "realistic nail arch, natural nail arch, photorealistic, ultra glossy, mirror-like, highly polished, waxed finish, car wax shine, "
        "mirror finish, crystal clear reflection, smooth as glass, wet look, high gloss, shiny surface, reflective, high detail, "
        "natural highlights and shadows, glossy, mirror, specular highlight, no color shift, no pattern change, no sticker effect, no flatness, no plastic look, no AI artifacts, "
        "glossy 3D highlights and reflections, "
        "perfect nail curvature, natural nail growth direction, proper nail length, realistic nail tip shape, "
        "natural nail bed shape, proper nail arch, realistic nail thickness, natural nail edge, "
        "professional nail salon quality, perfect nail form, natural nail structure"
    )
    negative_prompt = (
        "grainy, rough, artifact, noise, sandpaper, matte, dull, low detail, color shift, color change, overexposed, too bright, "
        "full-nail highlight, flat, 2d, no curvature, unnatural flatness, blocky, rigid, no arch, sticker, painting, cartoon, illustration, "
        "fake, ai, smooth, plastic, doll, no shadow, no highlight, unnatural, out of focus, overprocessed, "
        "wrong nail shape, deformed nail, unnatural nail length, flat nail surface, no nail arch, "
        "painted on effect, sticker effect, artificial nail shape, wrong nail direction"
    )
    def img2b64(path):
        with open(path, "rb") as f:
            return base64.b64encode(f.read()).decode()
    init_image = img2b64(orig_img_path)
    reference_image = img2b64(orig_img_path)

    # ç”ŸæˆCannyè¾¹ç¼˜å›¾ç”¨äºå½¢çŠ¶æ§åˆ¶
    def generate_canny_control(image_path, target_size):
        """ç”ŸæˆCannyè¾¹ç¼˜å›¾ç”¨äºå½¢çŠ¶æ§åˆ¶"""
        img = cv2.imread(image_path)
        if img is None:
            return None
        
        # è°ƒæ•´å°ºå¯¸
        img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)
        
        # è½¬æ¢ä¸ºç°åº¦
        gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
        
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # Cannyè¾¹ç¼˜æ£€æµ‹
        canny = cv2.Canny(blurred, 50, 150)
        
        # è½»å¾®è†¨èƒ€ä»¥å¢å¼ºè¾¹ç¼˜
        kernel = np.ones((2, 2), np.uint8)
        canny = cv2.dilate(canny, kernel, iterations=1)
        
        # è½¬æ¢ä¸ºPILå¹¶ç¼–ç 
        canny_pil = Image.fromarray(canny)
        buf = BytesIO()
        canny_pil.save(buf, format="PNG")
        return base64.b64encode(buf.getvalue()).decode()

    # ç”ŸæˆCannyæ§åˆ¶å›¾
    canny_control = generate_canny_control(orig_img_path, (target_w, target_h))

    payload = {
        "init_images": [init_image],
        "mask": mask_b64,
        "mask_blur": 8,
        "inpainting_fill": 1,
        "inpaint_full_res": True,
        "inpaint_full_res_padding": 32,
        "prompt": prompt_str,
        "negative_prompt": negative_prompt,
        "steps": 35,
        "width": target_w,
        "height": target_h,
        "sampler_name": "DPM++ 2M Karras",
        "cfg_scale": 8.5,
        "denoising_strength": 0.4,
        "seed": 123456789,
        "alwayson_scripts": {
            "controlnet": {
                "args": [
                    {
                        "enabled": True,
                        "input_image": reference_image,
                        "module": "reference_only",
                        "model": "None",
                        "weight": 0.8,
                        "resize_mode": "Just Resize",
                        "control_mode": "Balanced",
                    },
                    {
                        "enabled": True,
                        "input_image": canny_control,
                        "module": "canny",
                        "model": "control_v11p_sd15_canny [d14c016b]",
                        "weight": 1.2,
                        "resize_mode": "Just Resize",
                        "control_mode": "Balanced",
                        "lowvram": False,
                        "processor_res": 512,
                        "threshold_a": 50,
                        "threshold_b": 150,
                    }
                ]
            }
        },
        "script_name": None,
        "batch_size": 1,
        "mode": "inpaint",
        "override_settings": {
            "sd_model_checkpoint": "sd_xl_base_1.0"
        }
    }

    # ç›´æ¥è°ƒç”¨APIç”Ÿæˆ
    response = requests.post(
        "http://127.0.0.1:7860/sdapi/v1/img2img",
        json=payload
    )

    try:
        result = response.json()
        if 'images' in result and len(result['images']) > 0:
            output_dir = "data/output/final"
            os.makedirs(output_dir, exist_ok=True)
            out_path = os.path.join(output_dir, f"{orig_stem}_final.png")
            img_bytes = base64.b64decode(result['images'][0])
            tmp_path = os.path.join(output_dir, f"{orig_stem}_tmp.png")
            with open(tmp_path, "wb") as f:
                f.write(img_bytes)
            ai_img = Image.open(tmp_path).convert("RGB").resize((orig_w, orig_h), Image.LANCZOS)
            ai_img.save(out_path)
            os.remove(tmp_path)
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] AIç²¾ç‚¼æˆå“å›¾å·²ä¿å­˜åˆ° {out_path}")
            return out_path
        else:
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] æœªæ£€æµ‹åˆ°å›¾ç‰‡ï¼Œè¿”å›å†…å®¹ï¼š", result)
            return None
    except Exception as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] APIè¿”å›å†…å®¹æ— æ³•è§£æä¸ºJSONï¼ŒåŸå§‹å†…å®¹ï¼š")
        print(response.text)
        return None

# ç”¨æ³•ç¤ºä¾‹ï¼š
# refine_sdxl_pipeline('data/test_images/120745430.png') 

# ========== å¤šä»»åŠ¡ç®¡ç†å®ç”¨å‡½æ•° ==========
def list_all_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡ï¼ˆè¿è¡Œä¸­ã€ç­‰å¾…ä¸­ã€å·²å®Œæˆï¼‰"""
    task_info = WebUIProgressMonitor.get_task_info()
    if not task_info:
        print("æ— æ³•è·å–ä»»åŠ¡ä¿¡æ¯")
        return
    
    print("\n=== ä»»åŠ¡åˆ—è¡¨ ===")
    
    # è¿è¡Œä¸­çš„ä»»åŠ¡
    running_tasks = task_info.get('queue_running', [])
    if running_tasks:
        print(f"\nğŸŸ¢ è¿è¡Œä¸­çš„ä»»åŠ¡ ({len(running_tasks)}ä¸ª):")
        for i, task in enumerate(running_tasks, 1):
            task_id = task.get('id', 'unknown')
            prompt = task.get('prompt', '')[:50] + '...' if len(task.get('prompt', '')) > 50 else task.get('prompt', '')
            print(f"  {i}. ID: {task_id} | æç¤ºè¯: {prompt}")
    else:
        print("\nğŸŸ¢ è¿è¡Œä¸­çš„ä»»åŠ¡: æ— ")
    
    # ç­‰å¾…ä¸­çš„ä»»åŠ¡
    pending_tasks = task_info.get('queue_pending', [])
    if pending_tasks:
        print(f"\nğŸŸ¡ ç­‰å¾…ä¸­çš„ä»»åŠ¡ ({len(pending_tasks)}ä¸ª):")
        for i, task in enumerate(pending_tasks, 1):
            task_id = task.get('id', 'unknown')
            prompt = task.get('prompt', '')[:50] + '...' if len(task.get('prompt', '')) > 50 else task.get('prompt', '')
            print(f"  {i}. ID: {task_id} | æç¤ºè¯: {prompt}")
    else:
        print("\nğŸŸ¡ ç­‰å¾…ä¸­çš„ä»»åŠ¡: æ— ")
    
    # å·²å®Œæˆçš„ä»»åŠ¡
    completed_tasks = task_info.get('queue_history', [])
    if completed_tasks:
        print(f"\nğŸ”µ å·²å®Œæˆçš„ä»»åŠ¡ ({len(completed_tasks)}ä¸ª):")
        for i, task in enumerate(completed_tasks[-5:], 1):  # åªæ˜¾ç¤ºæœ€è¿‘5ä¸ª
            task_id = task.get('id', 'unknown')
            prompt = task.get('prompt', '')[:50] + '...' if len(task.get('prompt', '')) > 50 else task.get('prompt', '')
            print(f"  {i}. ID: {task_id} | æç¤ºè¯: {prompt}")
    else:
        print("\nğŸ”µ å·²å®Œæˆçš„ä»»åŠ¡: æ— ")

def find_task_by_keywords(keywords):
    """æ ¹æ®å…³é”®è¯æŸ¥æ‰¾ä»»åŠ¡"""
    task_info = WebUIProgressMonitor.get_task_info()
    if not task_info:
        print("æ— æ³•è·å–ä»»åŠ¡ä¿¡æ¯")
        return None
    
    result = WebUIProgressMonitor.find_task_by_prompt(task_info, target_prompt_keywords=keywords)
    if result:
        status = result['status']
        task = result['task']
        task_id = task.get('id', 'unknown')
        prompt = task.get('prompt', '')[:100] + '...' if len(task.get('prompt', '')) > 100 else task.get('prompt', '')
        
        print(f"\næ‰¾åˆ°ä»»åŠ¡:")
        print(f"  ID: {task_id}")
        print(f"  çŠ¶æ€: {status}")
        print(f"  æç¤ºè¯: {prompt}")
        return result
    else:
        print(f"æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ {keywords} çš„ä»»åŠ¡")
        return None

def monitor_task_by_id(task_id):
    """æ ¹æ®ä»»åŠ¡IDç›‘æ§ç‰¹å®šä»»åŠ¡"""
    print(f"å¼€å§‹ç›‘æ§ä»»åŠ¡ {task_id}...")
    success = WebUIProgressMonitor.monitor_specific_task(task_id)
    if success:
        print(f"ä»»åŠ¡ {task_id} ç›‘æ§å®Œæˆ")
    else:
        print(f"ä»»åŠ¡ {task_id} ç›‘æ§å¤±è´¥æˆ–è¶…æ—¶")
    return success

def monitor_task_by_keywords(keywords):
    """æ ¹æ®å…³é”®è¯ç›‘æ§ç‰¹å®šä»»åŠ¡"""
    print(f"å¼€å§‹ç›‘æ§åŒ…å«å…³é”®è¯ {keywords} çš„ä»»åŠ¡...")
    success = WebUIProgressMonitor.monitor_specific_task(keywords)
    if success:
        print(f"å…³é”®è¯ä»»åŠ¡ç›‘æ§å®Œæˆ")
    else:
        print(f"å…³é”®è¯ä»»åŠ¡ç›‘æ§å¤±è´¥æˆ–è¶…æ—¶")
    return success

# ========== è¿›åº¦ç›‘æ§ä½¿ç”¨è¯´æ˜ ==========
"""
WebUI è¿›åº¦ç›‘æ§åŠŸèƒ½è¯´æ˜ï¼š

1. HTTP æ–¹å¼ç›‘æ§ï¼ˆé»˜è®¤ï¼‰ï¼š
   - ä½¿ç”¨ /sdapi/v1/progress æ¥å£
   - æ¯ç§’è½®è¯¢ä¸€æ¬¡è¿›åº¦
   - è‡ªåŠ¨æ˜¾ç¤ºå½“å‰æ­¥éª¤å’Œç™¾åˆ†æ¯”

2. WebSocket æ–¹å¼ç›‘æ§ï¼ˆå¯é€‰ï¼‰ï¼š
   - éœ€è¦å®‰è£…ï¼špip install websocket-client
   - å®æ—¶æ¨é€è¿›åº¦æ›´æ–°
   - æ›´ä½çš„å»¶è¿Ÿå’Œèµ„æºæ¶ˆè€—

3. å¤šä»»åŠ¡ç®¡ç†åŠŸèƒ½ï¼š
   - åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡ï¼ˆè¿è¡Œä¸­ã€ç­‰å¾…ä¸­ã€å·²å®Œæˆï¼‰
   - æ ¹æ®å…³é”®è¯æŸ¥æ‰¾ç‰¹å®šä»»åŠ¡
   - æ ¹æ®ä»»åŠ¡IDç›‘æ§ç‰¹å®šä»»åŠ¡
   - æ”¯æŒå¤šä»»åŠ¡å¹¶å‘ç›‘æ§

4. è¿›åº¦ä¿¡æ¯åŒ…å«ï¼š
   - å½“å‰æ­¥éª¤ (sampling_step)
   - æ€»æ­¥éª¤æ•° (sampling_steps) 
   - å®Œæˆç™¾åˆ†æ¯”
   - ä»»åŠ¡çŠ¶æ€

5. ä½¿ç”¨ç¤ºä¾‹ï¼š
   # ç®€å•ç›‘æ§
   WebUIProgressMonitor.monitor_progress_http()
   
   # å¸¦å›è°ƒçš„ç›‘æ§
   def my_callback(current, total, percent):
       print(f"å¤„ç†è¿›åº¦: {percent:.1f}%")
   
   WebUIProgressMonitor.monitor_progress_http(my_callback)
   
   # WebSocketç›‘æ§
   WebUIProgressMonitor.monitor_progress_websocket(my_callback)
   
   # å¤šä»»åŠ¡ç®¡ç†
   list_all_tasks()  # åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
   find_task_by_keywords(['nail art', 'stiletto'])  # æŸ¥æ‰¾ç‰¹å®šä»»åŠ¡
   monitor_task_by_id('task_123')  # ç›‘æ§ç‰¹å®šä»»åŠ¡ID
   monitor_task_by_keywords(['nail art'])  # ç›‘æ§åŒ…å«å…³é”®è¯çš„ä»»åŠ¡

6. é˜Ÿåˆ—çŠ¶æ€æŸ¥è¯¢ï¼š
   queue_status = WebUIProgressMonitor.get_queue_status()
   print(f"é˜Ÿåˆ—çŠ¶æ€: {queue_status}")
   
7. åœ¨ refine_sdxl_pipeline ä¸­ä½¿ç”¨ï¼š
   # å¯ç”¨è¿›åº¦ç›‘æ§ï¼ˆé»˜è®¤ï¼‰
   refine_sdxl_pipeline(img, orig_stem)
   
   # ç¦ç”¨è¿›åº¦ç›‘æ§
   refine_sdxl_pipeline(img, orig_stem, enable_progress_monitor=False)
   
   # ç›‘æ§ç‰¹å®šä»»åŠ¡ï¼ˆæ ¹æ®å…³é”®è¯ï¼‰
   refine_sdxl_pipeline(img, orig_stem, task_keywords=['nail art', 'stiletto'])
""" 