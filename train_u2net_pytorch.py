# -*- coding: utf-8 -*-
"""
train_u2net_pytorch.py - è¶…é«˜é²æ£’æ€§æŒ‡ç”²åˆ†å‰²è®­ç»ƒè„šæœ¬

åŠŸèƒ½ï¼š
    - ä½¿ç”¨1606å¼ é¢„å¤„ç†åçš„é«˜è´¨é‡æ•°æ®è®­ç»ƒUÂ²-Netæ¨¡å‹
    - å®ç°è¶…é«˜é²æ£’æ€§çš„æŒ‡ç”²åˆ†å‰²æ•ˆæœ
    - è¶…å¼ºæ•°æ®å¢å¼ºç­–ç•¥
    - å¤šæŸå¤±å‡½æ•°ç»„åˆ
    - EMAã€æ ‡ç­¾å¹³æ»‘ç­‰å…ˆè¿›è®­ç»ƒæŠ€æœ¯
    - æ··åˆç²¾åº¦è®­ç»ƒï¼Œä¼˜åŒ–GPUä½¿ç”¨
    - TensorBoardå›¾å½¢åŒ–ç›‘æ§ç•Œé¢

æ•°æ®ï¼š
    - å›¾åƒ: data/training_precise/images (1606å¼ )
    - æ©ç : data/training_precise/masks (1606å¼ )
    - å°ºå¯¸: 1024é•¿è¾¹ï¼Œä¸æ¨ç†æ—¶å®Œå…¨ä¸€è‡´

è¾“å‡ºï¼š
    - æœ€ä¼˜æ¨¡å‹: models/u2net_nail_best.pth
    - è®­ç»ƒæ—¥å¿—: train_u2net_detailed.log
    - è®­ç»ƒæ›²çº¿: training_curves.png
    - TensorBoardæ—¥å¿—: runs/training_logs/

ä½œè€…ï¼šAIåŠ©æ‰‹ä¼˜åŒ–
"""
import os
import numpy as np
from PIL import Image
from glob import glob
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
import logging
import sys
import albumentations as A
from albumentations.pytorch import ToTensorV2
import matplotlib.pyplot as plt
from torch.cuda.amp import GradScaler, autocast
import time
from pathlib import Path
import cv2
from torch.utils.tensorboard import SummaryWriter
import matplotlib
from kornia.losses import LovaszHingeLoss  # æ–°å¢
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('train_u2net_detailed.log', encoding="utf-8"),
        logging.StreamHandler(sys.stdout)
    ]
)

# ------------------ è¶…é«˜é²æ£’æ€§æ•°æ®é›†å®šä¹‰ï¼ˆé€Ÿåº¦ä¼˜åŒ–ç‰ˆï¼‰ ------------------
class UltraRobustNailSegmentationDataset(Dataset):
    def __init__(self, image_paths, mask_paths, max_size=1024, is_train=True):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.max_size = max_size
        self.is_train = is_train
        
        # è¶…é«˜é²æ£’æ€§æ•°æ®å¢å¼ºç­–ç•¥ï¼ˆé€Ÿåº¦ä¼˜åŒ–ç‰ˆï¼‰
        if is_train:
            self.transform = A.Compose([
                # åŸºç¡€å‡ ä½•å˜æ¢ - ä¿æŒé²æ£’æ€§
                A.RandomRotate90(p=0.5),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.ShiftScaleRotate(
                    shift_limit=0.1,  # å‡å°‘shiftèŒƒå›´
                    scale_limit=0.2,   # å‡å°‘scaleèŒƒå›´
                    rotate_limit=30,    # å‡å°‘rotateèŒƒå›´
                    p=0.7              # é™ä½æ¦‚ç‡
                ),
                
                # æ™ºèƒ½ç¼©æ”¾ - å…ˆè°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
                A.LongestMaxSize(max_size=self.max_size, interpolation=cv2.INTER_LANCZOS4),
                A.PadIfNeeded(min_height=self.max_size, min_width=self.max_size, border_mode=cv2.BORDER_CONSTANT, p=1.0),
                
                # ç®€åŒ–éšæœºè£å‰ª - å‡å°‘è®¡ç®—
                A.RandomCrop(height=896, width=896, p=0.2),  # å‡å°‘æ¦‚ç‡å’Œå°ºå¯¸
                A.PadIfNeeded(min_height=1024, min_width=1024, border_mode=cv2.BORDER_CONSTANT, p=0.2),
                
                # ç®€åŒ–å¼¹æ€§å˜æ¢ - ä¿ç•™æ ¸å¿ƒé²æ£’æ€§
                A.OneOf([
                    A.ElasticTransform(alpha=100, sigma=100 * 0.05, p=0.3),  # å‡å°‘å‚æ•°
                    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),  # å‡å°‘steps
                    A.OpticalDistortion(distort_limit=0.4, p=0.3),            # å‡å°‘distort
                ], p=0.3),  # é™ä½æ•´ä½“æ¦‚ç‡
                
                # ç®€åŒ–å…‰ç…§å˜æ¢ - ä¿ç•™æ ¸å¿ƒæ•ˆæœ
                A.OneOf([
                    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.4),
                    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.4),
                    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.4),  # å‡å°‘clip_limit
                ], p=0.4),  # é™ä½æ¦‚ç‡
                
                # ç®€åŒ–é¢œè‰²å˜æ¢
                A.OneOf([
                    A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=0.3),
                    A.ChannelShuffle(p=0.2),
                    A.ToGray(p=0.1),
                ], p=0.3),
                
                # ç®€åŒ–å™ªå£°å’Œæ¨¡ç³Š
                A.OneOf([
                    A.GaussianBlur(blur_limit=(3, 7), p=0.3),  # å‡å°‘blurèŒƒå›´
                    A.MotionBlur(blur_limit=7, p=0.3),
                ], p=0.3),
                
                # ç®€åŒ–å¤šå°ºåº¦è®­ç»ƒ
                A.RandomScale(scale_limit=0.2, p=0.4),  # å‡å°‘scaleèŒƒå›´
                
                # æœ€ç»ˆè°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
                A.LongestMaxSize(max_size=self.max_size, interpolation=cv2.INTER_LANCZOS4),
                A.PadIfNeeded(min_height=self.max_size, min_width=self.max_size, border_mode=cv2.BORDER_CONSTANT),
                
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2(),
            ])
        else:
            # éªŒè¯æ—¶åªåšåŸºæœ¬å¤„ç†
            self.transform = A.Compose([
                A.LongestMaxSize(max_size=self.max_size, interpolation=cv2.INTER_LANCZOS4),
                A.PadIfNeeded(min_height=self.max_size, min_width=self.max_size, border_mode=cv2.BORDER_CONSTANT),
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2(),
            ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # è¯»å–å›¾åƒå’Œæ©ç 
        image = np.array(Image.open(self.image_paths[idx]).convert('RGB'))
        mask = np.array(Image.open(self.mask_paths[idx]).convert('L'))
        
        # åº”ç”¨å˜æ¢
        transformed = self.transform(image=image, mask=mask)
        img = transformed['image']
        mask = transformed['mask']
        
        # ç¡®ä¿æ©ç æ˜¯æµ®ç‚¹æ•°ä¸”èŒƒå›´åœ¨[0,1]
        mask = mask.float() / 255.0
        mask = mask.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦
        
        return img, mask

# ------------------ å¿«é€Ÿæ•°æ®å¢å¼ºç±» ------------------
class FastRobustNailSegmentationDataset(Dataset):
    """å¿«é€Ÿç‰ˆæœ¬çš„æ•°æ®é›†ï¼Œå‡å°‘æ•°æ®å¢å¼ºå¤æ‚åº¦ä½†ä¿æŒæ ¸å¿ƒé²æ£’æ€§"""
    def __init__(self, image_paths, mask_paths, max_size=1024, is_train=True):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.max_size = max_size
        self.is_train = is_train
        
        # å¿«é€Ÿä½†æœ‰æ•ˆçš„æ•°æ®å¢å¼ºç­–ç•¥
        if is_train:
            self.transform = A.Compose([
                # æ ¸å¿ƒå‡ ä½•å˜æ¢
                A.RandomRotate90(p=0.5),
                A.HorizontalFlip(p=0.5),
                A.ShiftScaleRotate(
                    shift_limit=0.1,
                    scale_limit=0.15,
                    rotate_limit=20,
                    p=0.6
                ),
                
                # åŸºç¡€ç¼©æ”¾
                A.LongestMaxSize(max_size=self.max_size, interpolation=cv2.INTER_LANCZOS4),
                A.PadIfNeeded(min_height=self.max_size, min_width=self.max_size, border_mode=cv2.BORDER_CONSTANT),
                
                # ç®€åŒ–å…‰ç…§å˜æ¢
                A.OneOf([
                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
                    A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=20, val_shift_limit=15, p=0.5),
                ], p=0.5),
                
                # ç®€åŒ–å™ªå£°
                A.GaussianBlur(blur_limit=(3, 5), p=0.3),
                
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2(),
            ])
        else:
            # éªŒè¯æ—¶åªåšåŸºæœ¬å¤„ç†
            self.transform = A.Compose([
                A.LongestMaxSize(max_size=self.max_size, interpolation=cv2.INTER_LANCZOS4),
                A.PadIfNeeded(min_height=self.max_size, min_width=self.max_size, border_mode=cv2.BORDER_CONSTANT),
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2(),
            ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # è¯»å–å›¾åƒå’Œæ©ç 
        image = np.array(Image.open(self.image_paths[idx]).convert('RGB'))
        mask = np.array(Image.open(self.mask_paths[idx]).convert('L'))
        
        # åº”ç”¨å˜æ¢
        transformed = self.transform(image=image, mask=mask)
        img = transformed['image']
        mask = transformed['mask']
        
        # ç¡®ä¿æ©ç æ˜¯æµ®ç‚¹æ•°ä¸”èŒƒå›´åœ¨[0,1]
        mask = mask.float() / 255.0
        mask = mask.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦
        
        return img, mask

# ------------------ U2NETæ¨¡å‹ç»“æ„ ------------------
from generate_initial_masks import U2NET

# ------------------ ç®€åŒ–å’Œç¨³å®šçš„æŸå¤±å‡½æ•° ------------------
class StableU2NetLoss(nn.Module):
    """ç®€åŒ–å’Œç¨³å®šçš„U2Netå¤šè¾“å‡ºæŸå¤±å‡½æ•°"""
    def __init__(self, weights=[0.0, 0.0, 0.0, 1.0, 0.8, 0.6, 0.4]):  # è·³è¿‡å‰3å±‚
        super(StableU2NetLoss, self).__init__()
        self.weights = weights
        self.bce_loss = nn.BCEWithLogitsLoss()
        self.dice_loss = DiceLoss()
    
    def forward(self, outputs, target):
        # outputs: (d0, d1, d2, d3, d4, d5, d6)
        # target: ç›®æ ‡æ©ç 
        bce_loss = 0
        dice_loss = 0
        
        for i, output in enumerate(outputs):
            if i < len(self.weights):
                weight = self.weights[i]
                # è·³è¿‡æƒé‡ä¸º0çš„å±‚ï¼ˆæœ‰é—®é¢˜çš„å‰3å±‚ï¼‰
                if weight > 0:
                    bce_loss += weight * self.bce_loss(output, target)
                    dice_loss += weight * self.dice_loss(output, target)
        
        # ç®€åŒ–çš„æŸå¤±ç»„åˆ
        total_loss = 0.6 * bce_loss + 0.4 * dice_loss
        return total_loss

class DiceLoss(nn.Module):
    """ç¨³å®šçš„DiceæŸå¤±å‡½æ•°"""
    def __init__(self, smooth=1e-6):
        super(DiceLoss, self).__init__()
        self.smooth = smooth
    
    def forward(self, pred, target):
        # ä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°ï¼Œå› ä¸ºè¾“å…¥æ˜¯logits
        pred_sigmoid = torch.sigmoid(pred)
        pred_flat = pred_sigmoid.view(-1)
        target_flat = target.view(-1)
        
        intersection = (pred_flat * target_flat).sum()
        dice_coeff = (2. * intersection + self.smooth) / (pred_flat.sum() + target_flat.sum() + self.smooth)
        
        return 1 - dice_coeff

# ------------------ Lovasz å¤šè¾“å‡ºæŸå¤±å‡½æ•° ------------------
class StableU2NetLovaszLoss(nn.Module):
    """U2Netå¤šè¾“å‡º Lovasz æŸå¤±å‡½æ•°ï¼ˆä¸»è¾“å‡º Lovaszï¼Œè¾…åŠ©è¾“å‡ºå¯é€‰ Dice/BCEï¼‰"""
    def __init__(self, weights=[0.0, 0.0, 0.0, 1.0, 0.8, 0.6, 0.4], aux_loss_type='dice'):
        super().__init__()
        self.weights = weights
        self.lovasz = LovaszHingeLoss()
        self.aux_loss_type = aux_loss_type
        if aux_loss_type == 'dice':
            self.aux_loss = DiceLoss()
        elif aux_loss_type == 'bce':
            self.aux_loss = nn.BCEWithLogitsLoss()
        else:
            raise ValueError(f"aux_loss_type must be 'dice' or 'bce', got {aux_loss_type}")

    def forward(self, outputs, target):
        # outputs: (d0, d1, d2, d3, d4, d5, d6)
        # target: (B, 1, H, W)
        lovasz_loss = 0
        aux_loss = 0
        for i, output in enumerate(outputs):
            if i < len(self.weights):
                weight = self.weights[i]
                if weight > 0:
                    if i == 0:
                        # Lovasz åªç”¨äºä¸»è¾“å‡ºï¼Œä¸” target éœ€å»æ‰ channel ç»´
                        lovasz_loss += weight * self.lovasz(output, target[:,0,:,:])
                    else:
                        aux_loss += weight * self.aux_loss(output, target)
        # åªç”¨ Lovasz + è¾…åŠ©æŸå¤±
        total_loss = 0.7 * lovasz_loss + 0.3 * aux_loss
        return total_loss

# ------------------ ç®€åŒ–æŸå¤±å‡½æ•°ï¼ˆç”¨äºè°ƒè¯•IoUé—®é¢˜ï¼‰ ------------------
class SimpleU2NetLoss(nn.Module):
    """ç®€åŒ–çš„U2NetæŸå¤±å‡½æ•°ï¼Œåªä½¿ç”¨ä¸»è¾“å‡º"""
    def __init__(self):
        super().__init__()
        self.bce_loss = nn.BCEWithLogitsLoss()
        self.dice_loss = DiceLoss()
    
    def forward(self, outputs, target):
        # åªä½¿ç”¨ä¸»è¾“å‡º (d0)
        pred = outputs[0]
        bce_loss = self.bce_loss(pred, target)
        dice_loss = self.dice_loss(pred, target)
        
        # ç®€å•ç»„åˆ
        total_loss = 0.5 * bce_loss + 0.5 * dice_loss
        return total_loss

class SimpleLovaszLoss(nn.Module):
    """ç®€åŒ–çš„LovaszæŸå¤±å‡½æ•°ï¼Œåªä½¿ç”¨ä¸»è¾“å‡º"""
    def __init__(self):
        super().__init__()
        self.lovasz = LovaszHingeLoss()
    
    def forward(self, outputs, target):
        # åªä½¿ç”¨ä¸»è¾“å‡º (d0)
        pred = outputs[0]
        # targetéœ€è¦å»æ‰channelç»´åº¦
        target_2d = target[:, 0, :, :]
        loss = self.lovasz(pred, target_2d)
        return loss

class SimpleLoss(nn.Module):
    """ç®€å•çš„æŸå¤±å‡½æ•°ï¼Œåªä½¿ç”¨ä¸»è¾“å‡º"""
    def __init__(self):
        super().__init__()
        self.bce = nn.BCEWithLogitsLoss()
    
    def forward(self, outputs, target):
        # åªä½¿ç”¨ä¸»è¾“å‡º (d0)
        pred = outputs[0]
        
        # ç¡®ä¿å½¢çŠ¶åŒ¹é…
        if pred.shape != target.shape:
            target = nn.functional.interpolate(target, size=pred.shape[2:], mode='nearest')
        
        return self.bce(pred, target)

# ------------------ EMAæ¨¡å‹ ------------------
class EMA:
    """æŒ‡æ•°ç§»åŠ¨å¹³å‡"""
    def __init__(self, model, decay=0.9999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}
        self.register()

    def register(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                self.backup[name] = param.data
                param.data = self.shadow[name]

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}

# ------------------ æ”¹è¿›çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆå¸¦è¯Šæ–­ï¼‰ ------------------
def calculate_metrics(pred, target, threshold=0.5, debug=False):
    """è®¡ç®—å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ï¼ˆå¸¦è¯¦ç»†è¯Šæ–­ï¼‰"""
    # ä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°ï¼Œå› ä¸ºè¾“å…¥æ˜¯logits
    pred_sigmoid = torch.sigmoid(pred)
    pred_binary = (pred_sigmoid > threshold).float()
    target_binary = (target > threshold).float()
    
    # è¯Šæ–­ä¿¡æ¯
    if debug:
        logging.info(f"ğŸ” IoUè¯Šæ–­ä¿¡æ¯:")
        logging.info(f"  pred_sigmoidèŒƒå›´: [{pred_sigmoid.min().item():.4f}, {pred_sigmoid.max().item():.4f}]")
        logging.info(f"  pred_binaryç»Ÿè®¡: 0={((pred_binary == 0).sum().item())}, 1={((pred_binary == 1).sum().item())}")
        logging.info(f"  target_binaryç»Ÿè®¡: 0={((target_binary == 0).sum().item())}, 1={((target_binary == 1).sum().item())}")
        logging.info(f"  threshold: {threshold}")
    
    # IoU
    intersection = (pred_binary * target_binary).sum()
    union = pred_binary.sum() + target_binary.sum() - intersection
    iou = (intersection / (union + 1e-6)).item()
    
    # Dice
    dice = (2 * intersection) / (pred_binary.sum() + target_binary.sum() + 1e-6)
    dice = dice.item()
    
    # ç²¾ç¡®åº¦å’Œå¬å›ç‡
    tp = (pred_binary * target_binary).sum().item()
    fp = (pred_binary * (1 - target_binary)).sum().item()
    fn = ((1 - pred_binary) * target_binary).sum().item()
    
    precision = tp / (tp + fp + 1e-6)
    recall = tp / (tp + fn + 1e-6)
    
    if debug:
        logging.info(f"  intersection: {intersection.item()}")
        logging.info(f"  union: {union.item()}")
        logging.info(f"  IoU: {iou:.6f}")
        logging.info(f"  Dice: {dice:.6f}")
        logging.info(f"  Precision: {precision:.6f}")
        logging.info(f"  Recall: {recall:.6f}")
    
    return {
        'iou': iou,
        'dice': dice,
        'precision': precision,
        'recall': recall
    }

def validate_data_quality(image_paths, mask_paths, sample_size=5):
    """éªŒè¯æ•°æ®è´¨é‡"""
    logging.info("ğŸ” éªŒè¯æ•°æ®è´¨é‡...")
    
    for i in range(min(sample_size, len(image_paths))):
        img_path = image_paths[i]
        mask_path = mask_paths[i]
        
        # è¯»å–å›¾åƒå’Œæ©ç 
        image = np.array(Image.open(img_path).convert('RGB'))
        mask = np.array(Image.open(mask_path).convert('L'))
        
        # æ£€æŸ¥åŸºæœ¬å±æ€§
        logging.info(f"  æ ·æœ¬{i+1}: {os.path.basename(img_path)}")
        logging.info(f"    å›¾åƒå½¢çŠ¶: {image.shape}, èŒƒå›´: [{image.min()}, {image.max()}]")
        logging.info(f"    æ©ç å½¢çŠ¶: {mask.shape}, èŒƒå›´: [{mask.min()}, {mask.max()}]")
        logging.info(f"    æ©ç éé›¶åƒç´ : {(mask > 0).sum()}/{mask.size} ({100*(mask > 0).sum()/mask.size:.2f}%)")
        
        # æ£€æŸ¥æ©ç æ˜¯å¦å…¨é»‘æˆ–å…¨ç™½
        if mask.max() == mask.min():
            logging.warning(f"    âš ï¸ æ©ç å¯èƒ½æœ‰é—®é¢˜: å…¨{('é»‘' if mask.max() == 0 else 'ç™½')}")
        
        # æ£€æŸ¥æ©ç æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ­£æ ·æœ¬
        positive_ratio = (mask > 0).sum() / mask.size
        if positive_ratio < 0.01:
            logging.warning(f"    âš ï¸ æ©ç æ­£æ ·æœ¬æ¯”ä¾‹è¿‡ä½: {positive_ratio:.4f}")
        elif positive_ratio > 0.99:
            logging.warning(f"    âš ï¸ æ©ç æ­£æ ·æœ¬æ¯”ä¾‹è¿‡é«˜: {positive_ratio:.4f}")

def adaptive_threshold(pred_sigmoid, target_binary, initial_threshold=0.5):
    """è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´"""
    # å¦‚æœIoUä¸º0ï¼Œå°è¯•ä¸åŒçš„é˜ˆå€¼
    best_iou = 0.0
    best_threshold = initial_threshold
    
    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:
        pred_binary = (pred_sigmoid > threshold).float()
        intersection = (pred_binary * target_binary).sum()
        union = pred_binary.sum() + target_binary.sum() - intersection
        iou = (intersection / (union + 1e-6)).item()
        
        if iou > best_iou:
            best_iou = iou
            best_threshold = threshold
    
    return best_threshold, best_iou

# ------------------ è®­ç»ƒä¸»æµç¨‹ ------------------
def get_image_mask_pairs(image_dir, mask_dir):
    """è·å–å›¾åƒ-æ©ç å¯¹"""
    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    image_paths = []
    mask_paths = []
    
    for img_name in image_files:
        base, _ = os.path.splitext(img_name)
        mask_name = f"{base}_mask.png"
        img_path = os.path.join(image_dir, img_name)
        mask_path = os.path.join(mask_dir, mask_name)
        
        if os.path.exists(mask_path):
            image_paths.append(img_path)
            mask_paths.append(mask_path)
        else:
            logging.warning(f"æ©ç ä¸å­˜åœ¨: {mask_path}")
    
    return image_paths, mask_paths

def plot_training_curves(train_metrics, val_metrics, save_path='training_curves.png'):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    epochs = range(1, len(train_metrics['loss']) + 1)
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # æŸå¤±æ›²çº¿
    axes[0, 0].plot(epochs, train_metrics['loss'], 'b-', label='Train Loss')
    axes[0, 0].plot(epochs, val_metrics['loss'], 'r-', label='Val Loss')
    axes[0, 0].set_title('Loss')
    axes[0, 0].legend()
    
    # IoUæ›²çº¿
    axes[0, 1].plot(epochs, train_metrics['iou'], 'b-', label='Train IoU')
    axes[0, 1].plot(epochs, val_metrics['iou'], 'r-', label='Val IoU')
    axes[0, 1].set_title('IoU')
    axes[0, 1].legend()
    
    # Diceæ›²çº¿
    axes[1, 0].plot(epochs, train_metrics['dice'], 'b-', label='Train Dice')
    axes[1, 0].plot(epochs, val_metrics['dice'], 'r-', label='Val Dice')
    axes[1, 0].set_title('Dice')
    axes[1, 0].legend()
    
    # ç²¾ç¡®åº¦æ›²çº¿
    axes[1, 1].plot(epochs, train_metrics['precision'], 'b-', label='Train Precision')
    axes[1, 1].plot(epochs, val_metrics['precision'], 'r-', label='Val Precision')
    axes[1, 1].set_title('Precision')
    axes[1, 1].legend()
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

def train():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    
    # åŸºæœ¬é…ç½®
    image_dir = 'data/training_precise/images'
    mask_dir = 'data/training_precise/masks'
    max_size = 1024
    batch_size = 4
    num_epochs = 120
    lr = 1e-4
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    logging.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è·å–æ•°æ®è·¯å¾„
    image_files, mask_files = get_image_mask_pairs(image_dir, mask_dir)
    if len(image_files) == 0:
        logging.error('æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å›¾ç‰‡å’Œæ©ç å¯¹')
        return
    
    logging.info(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒ-æ©ç å¯¹")
    
    # è®­ç»ƒéªŒè¯é›†åˆ’åˆ†
    X_train, X_val, y_train, y_val = train_test_split(
        image_files, mask_files, test_size=0.2, random_state=42
    )
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = UltraRobustNailSegmentationDataset(X_train, y_train, max_size, is_train=True)
    val_dataset = UltraRobustNailSegmentationDataset(X_val, y_val, max_size, is_train=False)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                             num_workers=0, pin_memory=False)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, 
                           num_workers=0, pin_memory=False)
    
    logging.info(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬, éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
    
    # åˆ›å»ºæ¨¡å‹
    model = U2NET(3, 1).to(device)
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    pretrained_path = 'models/u2net.pth'
    if os.path.exists(pretrained_path):
        try:
            model.load_state_dict(torch.load(pretrained_path, map_location=device))
            logging.info("æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
        except Exception as e:
            logging.warning(f"é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    # åˆ›å»ºæŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = SimpleLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)
    
    # è®­ç»ƒç›‘æ§
    best_val_iou = 0.0
    os.makedirs('models', exist_ok=True)
    save_path = 'models/u2net_nail.pth'
    
    logging.info("å¼€å§‹è®­ç»ƒ")
    
    for epoch in range(1, num_epochs+1):
        start_time = time.time()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_iou = 0.0
        train_dice = 0.0
        
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{num_epochs} [Train]')
        for batch_idx, (imgs, masks) in enumerate(train_pbar):
            imgs, masks = imgs.to(device), masks.to(device)
            
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = model(imgs)
            loss = criterion(outputs, masks)
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            # è®¡ç®—æŒ‡æ ‡
            with torch.no_grad():
                pred = outputs[0]
                metrics = calculate_metrics(pred, masks)
            
            train_loss += loss.item()
            train_iou += metrics['iou']
            train_dice += metrics['dice']
            
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'IoU': f'{metrics["iou"]:.4f}',
                'Dice': f'{metrics["dice"]:.4f}'
            })
        
        # è®¡ç®—å¹³å‡è®­ç»ƒæŒ‡æ ‡
        train_loss /= len(train_loader)
        train_iou /= len(train_loader)
        train_dice /= len(train_loader)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_iou = 0.0
        val_dice = 0.0
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch}/{num_epochs} [Val]')
            for imgs, masks in val_pbar:
                imgs, masks = imgs.to(device), masks.to(device)
                
                outputs = model(imgs)
                loss = criterion(outputs, masks)
                
                pred = outputs[0]
                metrics = calculate_metrics(pred, masks)
                
                val_loss += loss.item()
                val_iou += metrics['iou']
                val_dice += metrics['dice']
                
                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'IoU': f'{metrics["iou"]:.4f}',
                    'Dice': f'{metrics["dice"]:.4f}'
                })
        
        # è®¡ç®—å¹³å‡éªŒè¯æŒ‡æ ‡
        val_loss /= len(val_loader)
        val_iou /= len(val_loader)
        val_dice /= len(val_loader)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_loss)
        
        # è®°å½•æ—¥å¿—
        epoch_time = time.time() - start_time
        logging.info(f"Epoch {epoch}/{num_epochs} ({epoch_time:.1f}s)")
        logging.info(f"  Train: Loss={train_loss:.4f}, IoU={train_iou:.4f}, Dice={train_dice:.4f}")
        logging.info(f"  Val:   Loss={val_loss:.4f}, IoU={val_iou:.4f}, Dice={val_dice:.4f}")
        logging.info(f"  LR: {optimizer.param_groups[0]['lr']:.2e}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_iou > best_val_iou:
            best_val_iou = val_iou
            torch.save(model.state_dict(), save_path)
            logging.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹ (IoU: {val_iou:.4f})")
        
        # æ—©åœæ£€æŸ¥
        if epoch > 10 and val_iou == 0:
            logging.info("IoUæŒç»­ä¸º0ï¼Œåœæ­¢è®­ç»ƒ")
            break
    
    logging.info("è®­ç»ƒå®Œæˆ")

if __name__ == '__main__':
    train() 